Log file created at: 2015/09/06 13:58:05
Running on machine: AMD-RESEARCH
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0906 13:58:05.835170 16515 caffe.cpp:114] Use GPU with device ID 0
I0906 13:58:05.875704 16515 device.cpp:230] Number of platforms found:1
I0906 13:58:05.875743 16515 device.cpp:262] 	CL_PLATFORM_NAME	AMD Accelerated Parallel Processing
I0906 13:58:05.875757 16515 device.cpp:262] 	CL_PLATFORM_PROFILE	FULL_PROFILE
I0906 13:58:05.875763 16515 device.cpp:262] 	CL_PLATFORM_VERSION	OpenCL 2.0 AMD-APP.internal (1644.0)
I0906 13:58:05.875769 16515 device.cpp:262] 	CL_PLATFORM_VENDOR	Advanced Micro Devices, Inc.
I0906 13:58:05.875774 16515 device.cpp:262] 	CL_PLATFORM_EXTENSIONS	cl_khr_icd cl_amd_object_metadata cl_amd_event_callback cl_amd_offline_devices 
I0906 13:58:05.875783 16515 device.cpp:286] Number of devices found:1
I0906 13:58:05.875788 16515 device.cpp:288] 	DeviceID:	0x18ab2f0
I0906 13:58:05.875809 16515 device.cpp:366] 	 Device Type:	CL_DEVICE_TYPE_GPU
I0906 13:58:05.875818 16515 device.cpp:393] 	Is it integrated GPU?:	0
I0906 13:58:05.875823 16515 device.cpp:393] 	Max clock frequency MHz:	930
I0906 13:58:05.875829 16515 device.cpp:393] 	Host-Device unified mem:	0
I0906 13:58:05.875834 16515 device.cpp:393] 	ECC support:	0
I0906 13:58:05.875839 16515 device.cpp:393] 	Endian little:	1
I0906 13:58:05.875844 16515 device.cpp:393] 	Max compute units:	44
I0906 13:58:05.875849 16515 device.cpp:393] 	Max work group size:	256
I0906 13:58:05.875856 16515 device.cpp:393] 	Max work item dimensions:	3
I0906 13:58:05.875862 16515 device.cpp:393] 	Max work item sizes:	0x100
I0906 13:58:05.875869 16515 device.cpp:389] 	 CL_DEVICE_QUEUE_PROPERTIES:	CL_QUEUE_PROFILING_ENABLE
I0906 13:58:05.875875 16515 device.cpp:378] 	 CL_DEVICE_EXECUTION_CAPABILITIES:	CL_EXEC_KERNEL
I0906 13:58:05.875881 16515 device.cpp:393] 	Max mem alloc size:	4244635648
I0906 13:58:05.875886 16515 device.cpp:393] 	Global mem size:	16878927872
I0906 13:58:05.875891 16515 device.cpp:393] 	Local mem size:	32768
I0906 13:58:05.875902 16515 device.cpp:96] Picked device type : GPU 0
I0906 13:58:08.267483 16515 device.cpp:152] Build Program
I0906 13:58:08.267706 16515 caffe.cpp:122] Starting Optimization
I0906 13:58:08.267797 16515 solver.cpp:40] Initializing solver from parameters: 
test_iter: 1
test_interval: 1000
base_lr: 0.01
display: 1
max_iter: 10
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "models/bvlc_alexnet/caffe_alexnet_train"
solver_mode: GPU
net: "models/bvlc_alexnet/train_val_without_dropout.prototxt"
I0906 13:58:08.267910 16515 solver.cpp:81] Creating training net from net file: models/bvlc_alexnet/train_val_without_dropout.prototxt
I0906 13:58:08.269042 16515 net.cpp:288] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0906 13:58:08.269093 16515 net.cpp:288] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0906 13:58:08.269273 16515 net.cpp:43] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/yugao/imagenet_data_lmdb/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/yugao/imagenet_data_lmdb/ilsvrc12_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0906 13:58:08.269708 16515 net.cpp:68] Memory required for data: 0
I0906 13:58:08.269917 16515 layer_factory.hpp:74] Creating layer data
I0906 13:58:08.269971 16515 net.cpp:91] Creating Layer data
I0906 13:58:08.269992 16515 net.cpp:369] data -> data
I0906 13:58:08.270097 16515 net.cpp:369] data -> label
I0906 13:58:08.270122 16515 net.cpp:121] Setting up data
I0906 13:58:08.270134 16515 data_transformer.cpp:22] Loading mean file from: /home/yugao/imagenet_data_lmdb/imagenet_mean.binaryproto
I0906 13:58:08.279337 16515 db_lmdb.cpp:22] Opened lmdb /home/yugao/imagenet_data_lmdb/ilsvrc12_train_lmdb
I0906 13:58:08.279680 16515 data_layer.cpp:53] output data size: 100,3,227,227
I0906 13:58:08.311036 16515 base_data_layer.cpp:43] Initializing prefetch
I0906 13:58:08.311240 16515 base_data_layer.cpp:45] Prefetch initialized.
I0906 13:58:08.311303 16515 net.cpp:128] Top shape: 100 3 227 227 (15458700)
I0906 13:58:08.311313 16515 net.cpp:128] Top shape: 100 (100)
I0906 13:58:08.311318 16515 net.cpp:134] Memory required for data: 61835200
I0906 13:58:08.311352 16515 layer_factory.hpp:74] Creating layer conv1
I0906 13:58:08.311431 16515 net.cpp:91] Creating Layer conv1
I0906 13:58:08.311453 16515 net.cpp:411] conv1 <- data
I0906 13:58:08.311504 16515 net.cpp:369] conv1 -> conv1
I0906 13:58:08.311569 16515 net.cpp:121] Setting up conv1
I0906 13:58:08.316509 16515 net.cpp:128] Top shape: 100 96 55 55 (29040000)
I0906 13:58:08.316515 16515 net.cpp:134] Memory required for data: 177995200
I0906 13:58:08.316555 16515 layer_factory.hpp:74] Creating layer relu1
I0906 13:58:08.316577 16515 net.cpp:91] Creating Layer relu1
I0906 13:58:08.316583 16515 net.cpp:411] relu1 <- conv1
I0906 13:58:08.316597 16515 net.cpp:358] relu1 -> conv1 (in-place)
I0906 13:58:08.316606 16515 net.cpp:121] Setting up relu1
I0906 13:58:08.316615 16515 net.cpp:128] Top shape: 100 96 55 55 (29040000)
I0906 13:58:08.316619 16515 net.cpp:134] Memory required for data: 294155200
I0906 13:58:08.316623 16515 layer_factory.hpp:74] Creating layer norm1
I0906 13:58:08.316653 16515 net.cpp:91] Creating Layer norm1
I0906 13:58:08.316659 16515 net.cpp:411] norm1 <- conv1
I0906 13:58:08.316673 16515 net.cpp:369] norm1 -> norm1
I0906 13:58:08.316686 16515 net.cpp:121] Setting up norm1
I0906 13:58:08.316710 16515 net.cpp:128] Top shape: 100 96 55 55 (29040000)
I0906 13:58:08.316715 16515 net.cpp:134] Memory required for data: 410315200
I0906 13:58:08.316720 16515 layer_factory.hpp:74] Creating layer pool1
I0906 13:58:08.316745 16515 net.cpp:91] Creating Layer pool1
I0906 13:58:08.316750 16515 net.cpp:411] pool1 <- norm1
I0906 13:58:08.316763 16515 net.cpp:369] pool1 -> pool1
I0906 13:58:08.316776 16515 net.cpp:121] Setting up pool1
I0906 13:58:08.316805 16515 net.cpp:128] Top shape: 100 96 27 27 (6998400)
I0906 13:58:08.316809 16515 net.cpp:134] Memory required for data: 438308800
I0906 13:58:08.316814 16515 layer_factory.hpp:74] Creating layer conv2
I0906 13:58:08.316829 16515 net.cpp:91] Creating Layer conv2
I0906 13:58:08.316834 16515 net.cpp:411] conv2 <- pool1
I0906 13:58:08.316850 16515 net.cpp:369] conv2 -> conv2
I0906 13:58:08.316862 16515 net.cpp:121] Setting up conv2
I0906 13:58:08.356899 16515 net.cpp:128] Top shape: 100 256 27 27 (18662400)
I0906 13:58:08.356914 16515 net.cpp:134] Memory required for data: 512958400
I0906 13:58:08.356945 16515 layer_factory.hpp:74] Creating layer relu2
I0906 13:58:08.356967 16515 net.cpp:91] Creating Layer relu2
I0906 13:58:08.356978 16515 net.cpp:411] relu2 <- conv2
I0906 13:58:08.356998 16515 net.cpp:358] relu2 -> conv2 (in-place)
I0906 13:58:08.357012 16515 net.cpp:121] Setting up relu2
I0906 13:58:08.357022 16515 net.cpp:128] Top shape: 100 256 27 27 (18662400)
I0906 13:58:08.357025 16515 net.cpp:134] Memory required for data: 587608000
I0906 13:58:08.357030 16515 layer_factory.hpp:74] Creating layer norm2
I0906 13:58:08.357046 16515 net.cpp:91] Creating Layer norm2
I0906 13:58:08.357053 16515 net.cpp:411] norm2 <- conv2
I0906 13:58:08.357066 16515 net.cpp:369] norm2 -> norm2
I0906 13:58:08.357079 16515 net.cpp:121] Setting up norm2
I0906 13:58:08.357108 16515 net.cpp:128] Top shape: 100 256 27 27 (18662400)
I0906 13:58:08.357113 16515 net.cpp:134] Memory required for data: 662257600
I0906 13:58:08.357118 16515 layer_factory.hpp:74] Creating layer pool2
I0906 13:58:08.357146 16515 net.cpp:91] Creating Layer pool2
I0906 13:58:08.357152 16515 net.cpp:411] pool2 <- norm2
I0906 13:58:08.357166 16515 net.cpp:369] pool2 -> pool2
I0906 13:58:08.357177 16515 net.cpp:121] Setting up pool2
I0906 13:58:08.357200 16515 net.cpp:128] Top shape: 100 256 13 13 (4326400)
I0906 13:58:08.357204 16515 net.cpp:134] Memory required for data: 679563200
I0906 13:58:08.357259 16515 layer_factory.hpp:74] Creating layer conv3
I0906 13:58:08.357281 16515 net.cpp:91] Creating Layer conv3
I0906 13:58:08.357287 16515 net.cpp:411] conv3 <- pool2
I0906 13:58:08.357303 16515 net.cpp:369] conv3 -> conv3
I0906 13:58:08.357318 16515 net.cpp:121] Setting up conv3
I0906 13:58:08.475977 16515 net.cpp:128] Top shape: 100 384 13 13 (6489600)
I0906 13:58:08.475999 16515 net.cpp:134] Memory required for data: 705521600
I0906 13:58:08.476043 16515 layer_factory.hpp:74] Creating layer relu3
I0906 13:58:08.476078 16515 net.cpp:91] Creating Layer relu3
I0906 13:58:08.476093 16515 net.cpp:411] relu3 <- conv3
I0906 13:58:08.476120 16515 net.cpp:358] relu3 -> conv3 (in-place)
I0906 13:58:08.476137 16515 net.cpp:121] Setting up relu3
I0906 13:58:08.476147 16515 net.cpp:128] Top shape: 100 384 13 13 (6489600)
I0906 13:58:08.476151 16515 net.cpp:134] Memory required for data: 731480000
I0906 13:58:08.476156 16515 layer_factory.hpp:74] Creating layer conv4
I0906 13:58:08.476184 16515 net.cpp:91] Creating Layer conv4
I0906 13:58:08.476191 16515 net.cpp:411] conv4 <- conv3
I0906 13:58:08.476207 16515 net.cpp:369] conv4 -> conv4
I0906 13:58:08.476222 16515 net.cpp:121] Setting up conv4
I0906 13:58:08.500998 16519 data_layer.cpp:120] Prefetch batch: 189 ms.
I0906 13:58:08.501045 16519 data_layer.cpp:121]      Read time: 23.893 ms.
I0906 13:58:08.501054 16519 data_layer.cpp:122] Transform time: 163.51 ms.
I0906 13:58:08.563753 16515 net.cpp:128] Top shape: 100 384 13 13 (6489600)
I0906 13:58:08.563774 16515 net.cpp:134] Memory required for data: 757438400
I0906 13:58:08.563802 16515 layer_factory.hpp:74] Creating layer relu4
I0906 13:58:08.563835 16515 net.cpp:91] Creating Layer relu4
I0906 13:58:08.563849 16515 net.cpp:411] relu4 <- conv4
I0906 13:58:08.563876 16515 net.cpp:358] relu4 -> conv4 (in-place)
I0906 13:58:08.563892 16515 net.cpp:121] Setting up relu4
I0906 13:58:08.563902 16515 net.cpp:128] Top shape: 100 384 13 13 (6489600)
I0906 13:58:08.563906 16515 net.cpp:134] Memory required for data: 783396800
I0906 13:58:08.563911 16515 layer_factory.hpp:74] Creating layer conv5
I0906 13:58:08.563946 16515 net.cpp:91] Creating Layer conv5
I0906 13:58:08.563951 16515 net.cpp:411] conv5 <- conv4
I0906 13:58:08.563968 16515 net.cpp:369] conv5 -> conv5
I0906 13:58:08.563982 16515 net.cpp:121] Setting up conv5
I0906 13:58:08.621495 16515 net.cpp:128] Top shape: 100 256 13 13 (4326400)
I0906 13:58:08.621512 16515 net.cpp:134] Memory required for data: 800702400
I0906 13:58:08.621553 16515 layer_factory.hpp:74] Creating layer relu5
I0906 13:58:08.621584 16515 net.cpp:91] Creating Layer relu5
I0906 13:58:08.621598 16515 net.cpp:411] relu5 <- conv5
I0906 13:58:08.621623 16515 net.cpp:358] relu5 -> conv5 (in-place)
I0906 13:58:08.621639 16515 net.cpp:121] Setting up relu5
I0906 13:58:08.621649 16515 net.cpp:128] Top shape: 100 256 13 13 (4326400)
I0906 13:58:08.621652 16515 net.cpp:134] Memory required for data: 818008000
I0906 13:58:08.621657 16515 layer_factory.hpp:74] Creating layer pool5
I0906 13:58:08.621677 16515 net.cpp:91] Creating Layer pool5
I0906 13:58:08.621683 16515 net.cpp:411] pool5 <- conv5
I0906 13:58:08.621697 16515 net.cpp:369] pool5 -> pool5
I0906 13:58:08.621711 16515 net.cpp:121] Setting up pool5
I0906 13:58:08.621732 16515 net.cpp:128] Top shape: 100 256 6 6 (921600)
I0906 13:58:08.621737 16515 net.cpp:134] Memory required for data: 821694400
I0906 13:58:08.621742 16515 layer_factory.hpp:74] Creating layer fc6
I0906 13:58:08.621778 16515 net.cpp:91] Creating Layer fc6
I0906 13:58:08.621783 16515 net.cpp:411] fc6 <- pool5
I0906 13:58:08.621798 16515 net.cpp:369] fc6 -> fc6
I0906 13:58:08.621812 16515 net.cpp:121] Setting up fc6
I0906 13:58:13.492439 16515 net.cpp:128] Top shape: 100 4096 (409600)
I0906 13:58:13.492465 16515 net.cpp:134] Memory required for data: 823332800
I0906 13:58:13.492493 16515 layer_factory.hpp:74] Creating layer relu6
I0906 13:58:13.492527 16515 net.cpp:91] Creating Layer relu6
I0906 13:58:13.492542 16515 net.cpp:411] relu6 <- fc6
I0906 13:58:13.492568 16515 net.cpp:358] relu6 -> fc6 (in-place)
I0906 13:58:13.492630 16515 net.cpp:121] Setting up relu6
I0906 13:58:13.492640 16515 net.cpp:128] Top shape: 100 4096 (409600)
I0906 13:58:13.492643 16515 net.cpp:134] Memory required for data: 824971200
I0906 13:58:13.492648 16515 layer_factory.hpp:74] Creating layer fc7
I0906 13:58:13.492671 16515 net.cpp:91] Creating Layer fc7
I0906 13:58:13.492677 16515 net.cpp:411] fc7 <- fc6
I0906 13:58:13.492693 16515 net.cpp:369] fc7 -> fc7
I0906 13:58:13.492708 16515 net.cpp:121] Setting up fc7
I0906 13:58:15.661120 16515 net.cpp:128] Top shape: 100 4096 (409600)
I0906 13:58:15.661144 16515 net.cpp:134] Memory required for data: 826609600
I0906 13:58:15.661171 16515 layer_factory.hpp:74] Creating layer relu7
I0906 13:58:15.661205 16515 net.cpp:91] Creating Layer relu7
I0906 13:58:15.661221 16515 net.cpp:411] relu7 <- fc7
I0906 13:58:15.661247 16515 net.cpp:358] relu7 -> fc7 (in-place)
I0906 13:58:15.661263 16515 net.cpp:121] Setting up relu7
I0906 13:58:15.661273 16515 net.cpp:128] Top shape: 100 4096 (409600)
I0906 13:58:15.661276 16515 net.cpp:134] Memory required for data: 828248000
I0906 13:58:15.661281 16515 layer_factory.hpp:74] Creating layer fc8
I0906 13:58:15.661304 16515 net.cpp:91] Creating Layer fc8
I0906 13:58:15.661310 16515 net.cpp:411] fc8 <- fc7
I0906 13:58:15.661325 16515 net.cpp:369] fc8 -> fc8
I0906 13:58:15.661340 16515 net.cpp:121] Setting up fc8
I0906 13:58:16.190832 16515 net.cpp:128] Top shape: 100 1000 (100000)
I0906 13:58:16.190855 16515 net.cpp:134] Memory required for data: 828648000
I0906 13:58:16.190881 16515 layer_factory.hpp:74] Creating layer loss
I0906 13:58:16.190932 16515 net.cpp:91] Creating Layer loss
I0906 13:58:16.190946 16515 net.cpp:411] loss <- fc8
I0906 13:58:16.190969 16515 net.cpp:411] loss <- label
I0906 13:58:16.190989 16515 net.cpp:369] loss -> loss
I0906 13:58:16.191009 16515 net.cpp:121] Setting up loss
I0906 13:58:16.191030 16515 layer_factory.hpp:74] Creating layer loss
I0906 13:58:16.191588 16515 net.cpp:128] Top shape: (1)
I0906 13:58:16.191593 16515 net.cpp:130]     with loss weight 1
I0906 13:58:16.191611 16515 net.cpp:134] Memory required for data: 828648004
I0906 13:58:16.191619 16515 net.cpp:193] loss needs backward computation.
I0906 13:58:16.191627 16515 net.cpp:193] fc8 needs backward computation.
I0906 13:58:16.191633 16515 net.cpp:193] relu7 needs backward computation.
I0906 13:58:16.191639 16515 net.cpp:193] fc7 needs backward computation.
I0906 13:58:16.191644 16515 net.cpp:193] relu6 needs backward computation.
I0906 13:58:16.191650 16515 net.cpp:193] fc6 needs backward computation.
I0906 13:58:16.191655 16515 net.cpp:193] pool5 needs backward computation.
I0906 13:58:16.191661 16515 net.cpp:193] relu5 needs backward computation.
I0906 13:58:16.191666 16515 net.cpp:193] conv5 needs backward computation.
I0906 13:58:16.191673 16515 net.cpp:193] relu4 needs backward computation.
I0906 13:58:16.191678 16515 net.cpp:193] conv4 needs backward computation.
I0906 13:58:16.191684 16515 net.cpp:193] relu3 needs backward computation.
I0906 13:58:16.191689 16515 net.cpp:193] conv3 needs backward computation.
I0906 13:58:16.191696 16515 net.cpp:193] pool2 needs backward computation.
I0906 13:58:16.191702 16515 net.cpp:193] norm2 needs backward computation.
I0906 13:58:16.191709 16515 net.cpp:193] relu2 needs backward computation.
I0906 13:58:16.191714 16515 net.cpp:193] conv2 needs backward computation.
I0906 13:58:16.191720 16515 net.cpp:193] pool1 needs backward computation.
I0906 13:58:16.191725 16515 net.cpp:193] norm1 needs backward computation.
I0906 13:58:16.191731 16515 net.cpp:193] relu1 needs backward computation.
I0906 13:58:16.191737 16515 net.cpp:193] conv1 needs backward computation.
I0906 13:58:16.191745 16515 net.cpp:195] data does not need backward computation.
I0906 13:58:16.191753 16515 net.cpp:236] This network produces output loss
I0906 13:58:16.191787 16515 net.cpp:483] Collecting Learning Rate and Weight Decay.
I0906 13:58:16.191803 16515 net.cpp:248] Network initialization done.
I0906 13:58:16.191807 16515 net.cpp:249] Memory required for data: 828648004
I0906 13:58:16.192769 16515 solver.cpp:165] Creating test net (#0) specified by net file: models/bvlc_alexnet/train_val_without_dropout.prototxt
I0906 13:58:16.192881 16515 net.cpp:288] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0906 13:58:16.193114 16515 net.cpp:43] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/yugao/imagenet_data_lmdb/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/yugao/imagenet_data_lmdb/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0906 13:58:16.193480 16515 net.cpp:68] Memory required for data: 0
I0906 13:58:16.193527 16515 layer_factory.hpp:74] Creating layer data
I0906 13:58:16.193549 16515 net.cpp:91] Creating Layer data
I0906 13:58:16.193559 16515 net.cpp:369] data -> data
I0906 13:58:16.193583 16515 net.cpp:369] data -> label
I0906 13:58:16.193595 16515 net.cpp:121] Setting up data
I0906 13:58:16.193603 16515 data_transformer.cpp:22] Loading mean file from: /home/yugao/imagenet_data_lmdb/imagenet_mean.binaryproto
I0906 13:58:16.202100 16515 db_lmdb.cpp:22] Opened lmdb /home/yugao/imagenet_data_lmdb/ilsvrc12_val_lmdb
I0906 13:58:16.202343 16515 data_layer.cpp:53] output data size: 50,3,227,227
I0906 13:58:16.219017 16515 base_data_layer.cpp:43] Initializing prefetch
I0906 13:58:16.219137 16515 base_data_layer.cpp:45] Prefetch initialized.
I0906 13:58:16.219171 16515 net.cpp:128] Top shape: 50 3 227 227 (7729350)
I0906 13:58:16.219179 16515 net.cpp:128] Top shape: 50 (50)
I0906 13:58:16.219183 16515 net.cpp:134] Memory required for data: 30917600
I0906 13:58:16.219214 16515 layer_factory.hpp:74] Creating layer label_data_1_split
I0906 13:58:16.219279 16515 net.cpp:91] Creating Layer label_data_1_split
I0906 13:58:16.219293 16515 net.cpp:411] label_data_1_split <- label
I0906 13:58:16.219367 16515 net.cpp:369] label_data_1_split -> label_data_1_split_0
I0906 13:58:16.219409 16515 net.cpp:369] label_data_1_split -> label_data_1_split_1
I0906 13:58:16.219420 16515 net.cpp:121] Setting up label_data_1_split
I0906 13:58:16.219455 16515 net.cpp:128] Top shape: 50 (50)
I0906 13:58:16.219462 16515 net.cpp:128] Top shape: 50 (50)
I0906 13:58:16.219466 16515 net.cpp:134] Memory required for data: 30918000
I0906 13:58:16.219471 16515 layer_factory.hpp:74] Creating layer conv1
I0906 13:58:16.219508 16515 net.cpp:91] Creating Layer conv1
I0906 13:58:16.219513 16515 net.cpp:411] conv1 <- data
I0906 13:58:16.219530 16515 net.cpp:369] conv1 -> conv1
I0906 13:58:16.219545 16515 net.cpp:121] Setting up conv1
I0906 13:58:16.224315 16515 net.cpp:128] Top shape: 50 96 55 55 (14520000)
I0906 13:58:16.224321 16515 net.cpp:134] Memory required for data: 88998000
I0906 13:58:16.224341 16515 layer_factory.hpp:74] Creating layer relu1
I0906 13:58:16.224354 16515 net.cpp:91] Creating Layer relu1
I0906 13:58:16.224360 16515 net.cpp:411] relu1 <- conv1
I0906 13:58:16.224372 16515 net.cpp:358] relu1 -> conv1 (in-place)
I0906 13:58:16.224382 16515 net.cpp:121] Setting up relu1
I0906 13:58:16.224390 16515 net.cpp:128] Top shape: 50 96 55 55 (14520000)
I0906 13:58:16.224393 16515 net.cpp:134] Memory required for data: 147078000
I0906 13:58:16.224398 16515 layer_factory.hpp:74] Creating layer norm1
I0906 13:58:16.224417 16515 net.cpp:91] Creating Layer norm1
I0906 13:58:16.224423 16515 net.cpp:411] norm1 <- conv1
I0906 13:58:16.224436 16515 net.cpp:369] norm1 -> norm1
I0906 13:58:16.224447 16515 net.cpp:121] Setting up norm1
I0906 13:58:16.224465 16515 net.cpp:128] Top shape: 50 96 55 55 (14520000)
I0906 13:58:16.224508 16515 net.cpp:134] Memory required for data: 205158000
I0906 13:58:16.224514 16515 layer_factory.hpp:74] Creating layer pool1
I0906 13:58:16.224529 16515 net.cpp:91] Creating Layer pool1
I0906 13:58:16.224534 16515 net.cpp:411] pool1 <- norm1
I0906 13:58:16.224547 16515 net.cpp:369] pool1 -> pool1
I0906 13:58:16.224558 16515 net.cpp:121] Setting up pool1
I0906 13:58:16.224576 16515 net.cpp:128] Top shape: 50 96 27 27 (3499200)
I0906 13:58:16.224581 16515 net.cpp:134] Memory required for data: 219154800
I0906 13:58:16.224586 16515 layer_factory.hpp:74] Creating layer conv2
I0906 13:58:16.224601 16515 net.cpp:91] Creating Layer conv2
I0906 13:58:16.224606 16515 net.cpp:411] conv2 <- pool1
I0906 13:58:16.224620 16515 net.cpp:369] conv2 -> conv2
I0906 13:58:16.224632 16515 net.cpp:121] Setting up conv2
I0906 13:58:16.264878 16515 net.cpp:128] Top shape: 50 256 27 27 (9331200)
I0906 13:58:16.264889 16515 net.cpp:134] Memory required for data: 256479600
I0906 13:58:16.264916 16515 layer_factory.hpp:74] Creating layer relu2
I0906 13:58:16.264937 16515 net.cpp:91] Creating Layer relu2
I0906 13:58:16.264946 16515 net.cpp:411] relu2 <- conv2
I0906 13:58:16.264966 16515 net.cpp:358] relu2 -> conv2 (in-place)
I0906 13:58:16.264978 16515 net.cpp:121] Setting up relu2
I0906 13:58:16.264987 16515 net.cpp:128] Top shape: 50 256 27 27 (9331200)
I0906 13:58:16.264991 16515 net.cpp:134] Memory required for data: 293804400
I0906 13:58:16.264997 16515 layer_factory.hpp:74] Creating layer norm2
I0906 13:58:16.265015 16515 net.cpp:91] Creating Layer norm2
I0906 13:58:16.265022 16515 net.cpp:411] norm2 <- conv2
I0906 13:58:16.265035 16515 net.cpp:369] norm2 -> norm2
I0906 13:58:16.265050 16515 net.cpp:121] Setting up norm2
I0906 13:58:16.265072 16515 net.cpp:128] Top shape: 50 256 27 27 (9331200)
I0906 13:58:16.265077 16515 net.cpp:134] Memory required for data: 331129200
I0906 13:58:16.265082 16515 layer_factory.hpp:74] Creating layer pool2
I0906 13:58:16.265097 16515 net.cpp:91] Creating Layer pool2
I0906 13:58:16.265103 16515 net.cpp:411] pool2 <- norm2
I0906 13:58:16.265116 16515 net.cpp:369] pool2 -> pool2
I0906 13:58:16.265127 16515 net.cpp:121] Setting up pool2
I0906 13:58:16.265149 16515 net.cpp:128] Top shape: 50 256 13 13 (2163200)
I0906 13:58:16.265153 16515 net.cpp:134] Memory required for data: 339782000
I0906 13:58:16.265158 16515 layer_factory.hpp:74] Creating layer conv3
I0906 13:58:16.265179 16515 net.cpp:91] Creating Layer conv3
I0906 13:58:16.265184 16515 net.cpp:411] conv3 <- pool2
I0906 13:58:16.265200 16515 net.cpp:369] conv3 -> conv3
I0906 13:58:16.265213 16515 net.cpp:121] Setting up conv3
I0906 13:58:16.312928 16520 data_layer.cpp:120] Prefetch batch: 93 ms.
I0906 13:58:16.312959 16520 data_layer.cpp:121]      Read time: 12.075 ms.
I0906 13:58:16.312966 16520 data_layer.cpp:122] Transform time: 80.513 ms.
I0906 13:58:16.381564 16515 net.cpp:128] Top shape: 50 384 13 13 (3244800)
I0906 13:58:16.381587 16515 net.cpp:134] Memory required for data: 352761200
I0906 13:58:16.381628 16515 layer_factory.hpp:74] Creating layer relu3
I0906 13:58:16.381660 16515 net.cpp:91] Creating Layer relu3
I0906 13:58:16.381675 16515 net.cpp:411] relu3 <- conv3
I0906 13:58:16.381700 16515 net.cpp:358] relu3 -> conv3 (in-place)
I0906 13:58:16.381717 16515 net.cpp:121] Setting up relu3
I0906 13:58:16.381726 16515 net.cpp:128] Top shape: 50 384 13 13 (3244800)
I0906 13:58:16.381731 16515 net.cpp:134] Memory required for data: 365740400
I0906 13:58:16.381734 16515 layer_factory.hpp:74] Creating layer conv4
I0906 13:58:16.381762 16515 net.cpp:91] Creating Layer conv4
I0906 13:58:16.381767 16515 net.cpp:411] conv4 <- conv3
I0906 13:58:16.381783 16515 net.cpp:369] conv4 -> conv4
I0906 13:58:16.381798 16515 net.cpp:121] Setting up conv4
I0906 13:58:16.468471 16515 net.cpp:128] Top shape: 50 384 13 13 (3244800)
I0906 13:58:16.468492 16515 net.cpp:134] Memory required for data: 378719600
I0906 13:58:16.468518 16515 layer_factory.hpp:74] Creating layer relu4
I0906 13:58:16.468550 16515 net.cpp:91] Creating Layer relu4
I0906 13:58:16.468605 16515 net.cpp:411] relu4 <- conv4
I0906 13:58:16.468633 16515 net.cpp:358] relu4 -> conv4 (in-place)
I0906 13:58:16.468649 16515 net.cpp:121] Setting up relu4
I0906 13:58:16.468658 16515 net.cpp:128] Top shape: 50 384 13 13 (3244800)
I0906 13:58:16.468662 16515 net.cpp:134] Memory required for data: 391698800
I0906 13:58:16.468667 16515 layer_factory.hpp:74] Creating layer conv5
I0906 13:58:16.468694 16515 net.cpp:91] Creating Layer conv5
I0906 13:58:16.468700 16515 net.cpp:411] conv5 <- conv4
I0906 13:58:16.468716 16515 net.cpp:369] conv5 -> conv5
I0906 13:58:16.468731 16515 net.cpp:121] Setting up conv5
I0906 13:58:16.526487 16515 net.cpp:128] Top shape: 50 256 13 13 (2163200)
I0906 13:58:16.526507 16515 net.cpp:134] Memory required for data: 400351600
I0906 13:58:16.526547 16515 layer_factory.hpp:74] Creating layer relu5
I0906 13:58:16.526577 16515 net.cpp:91] Creating Layer relu5
I0906 13:58:16.526590 16515 net.cpp:411] relu5 <- conv5
I0906 13:58:16.526614 16515 net.cpp:358] relu5 -> conv5 (in-place)
I0906 13:58:16.526630 16515 net.cpp:121] Setting up relu5
I0906 13:58:16.526639 16515 net.cpp:128] Top shape: 50 256 13 13 (2163200)
I0906 13:58:16.526643 16515 net.cpp:134] Memory required for data: 409004400
I0906 13:58:16.526648 16515 layer_factory.hpp:74] Creating layer pool5
I0906 13:58:16.526676 16515 net.cpp:91] Creating Layer pool5
I0906 13:58:16.526682 16515 net.cpp:411] pool5 <- conv5
I0906 13:58:16.526696 16515 net.cpp:369] pool5 -> pool5
I0906 13:58:16.526710 16515 net.cpp:121] Setting up pool5
I0906 13:58:16.526731 16515 net.cpp:128] Top shape: 50 256 6 6 (460800)
I0906 13:58:16.526734 16515 net.cpp:134] Memory required for data: 410847600
I0906 13:58:16.526739 16515 layer_factory.hpp:74] Creating layer fc6
I0906 13:58:16.526762 16515 net.cpp:91] Creating Layer fc6
I0906 13:58:16.526767 16515 net.cpp:411] fc6 <- pool5
I0906 13:58:16.526782 16515 net.cpp:369] fc6 -> fc6
I0906 13:58:16.526794 16515 net.cpp:121] Setting up fc6
I0906 13:58:21.365124 16515 net.cpp:128] Top shape: 50 4096 (204800)
I0906 13:58:21.365149 16515 net.cpp:134] Memory required for data: 411666800
I0906 13:58:21.365176 16515 layer_factory.hpp:74] Creating layer relu6
I0906 13:58:21.365211 16515 net.cpp:91] Creating Layer relu6
I0906 13:58:21.365226 16515 net.cpp:411] relu6 <- fc6
I0906 13:58:21.365250 16515 net.cpp:358] relu6 -> fc6 (in-place)
I0906 13:58:21.365267 16515 net.cpp:121] Setting up relu6
I0906 13:58:21.365277 16515 net.cpp:128] Top shape: 50 4096 (204800)
I0906 13:58:21.365280 16515 net.cpp:134] Memory required for data: 412486000
I0906 13:58:21.365285 16515 layer_factory.hpp:74] Creating layer fc7
I0906 13:58:21.365309 16515 net.cpp:91] Creating Layer fc7
I0906 13:58:21.365314 16515 net.cpp:411] fc7 <- fc6
I0906 13:58:21.365330 16515 net.cpp:369] fc7 -> fc7
I0906 13:58:21.365345 16515 net.cpp:121] Setting up fc7
I0906 13:58:23.510701 16515 net.cpp:128] Top shape: 50 4096 (204800)
I0906 13:58:23.510725 16515 net.cpp:134] Memory required for data: 413305200
I0906 13:58:23.510752 16515 layer_factory.hpp:74] Creating layer relu7
I0906 13:58:23.510785 16515 net.cpp:91] Creating Layer relu7
I0906 13:58:23.510800 16515 net.cpp:411] relu7 <- fc7
I0906 13:58:23.510828 16515 net.cpp:358] relu7 -> fc7 (in-place)
I0906 13:58:23.510844 16515 net.cpp:121] Setting up relu7
I0906 13:58:23.510854 16515 net.cpp:128] Top shape: 50 4096 (204800)
I0906 13:58:23.510857 16515 net.cpp:134] Memory required for data: 414124400
I0906 13:58:23.510862 16515 layer_factory.hpp:74] Creating layer fc8
I0906 13:58:23.510885 16515 net.cpp:91] Creating Layer fc8
I0906 13:58:23.510890 16515 net.cpp:411] fc8 <- fc7
I0906 13:58:23.510906 16515 net.cpp:369] fc8 -> fc8
I0906 13:58:23.510932 16515 net.cpp:121] Setting up fc8
I0906 13:58:24.034812 16515 net.cpp:128] Top shape: 50 1000 (50000)
I0906 13:58:24.034833 16515 net.cpp:134] Memory required for data: 414324400
I0906 13:58:24.034860 16515 layer_factory.hpp:74] Creating layer fc8_fc8_0_split
I0906 13:58:24.034893 16515 net.cpp:91] Creating Layer fc8_fc8_0_split
I0906 13:58:24.034958 16515 net.cpp:411] fc8_fc8_0_split <- fc8
I0906 13:58:24.034988 16515 net.cpp:369] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0906 13:58:24.035012 16515 net.cpp:369] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0906 13:58:24.035023 16515 net.cpp:121] Setting up fc8_fc8_0_split
I0906 13:58:24.035040 16515 net.cpp:128] Top shape: 50 1000 (50000)
I0906 13:58:24.035046 16515 net.cpp:128] Top shape: 50 1000 (50000)
I0906 13:58:24.035050 16515 net.cpp:134] Memory required for data: 414724400
I0906 13:58:24.035055 16515 layer_factory.hpp:74] Creating layer accuracy
I0906 13:58:24.035086 16515 net.cpp:91] Creating Layer accuracy
I0906 13:58:24.035092 16515 net.cpp:411] accuracy <- fc8_fc8_0_split_0
I0906 13:58:24.035104 16515 net.cpp:411] accuracy <- label_data_1_split_0
I0906 13:58:24.035115 16515 net.cpp:369] accuracy -> accuracy
I0906 13:58:24.035126 16515 net.cpp:121] Setting up accuracy
I0906 13:58:24.035143 16515 net.cpp:128] Top shape: (1)
I0906 13:58:24.035147 16515 net.cpp:134] Memory required for data: 414724404
I0906 13:58:24.035152 16515 layer_factory.hpp:74] Creating layer loss
I0906 13:58:24.035163 16515 net.cpp:91] Creating Layer loss
I0906 13:58:24.035168 16515 net.cpp:411] loss <- fc8_fc8_0_split_1
I0906 13:58:24.035179 16515 net.cpp:411] loss <- label_data_1_split_1
I0906 13:58:24.035190 16515 net.cpp:369] loss -> loss
I0906 13:58:24.035202 16515 net.cpp:121] Setting up loss
I0906 13:58:24.035212 16515 layer_factory.hpp:74] Creating layer loss
I0906 13:58:24.035562 16515 net.cpp:128] Top shape: (1)
I0906 13:58:24.035567 16515 net.cpp:130]     with loss weight 1
I0906 13:58:24.035583 16515 net.cpp:134] Memory required for data: 414724408
I0906 13:58:24.035591 16515 net.cpp:193] loss needs backward computation.
I0906 13:58:24.035598 16515 net.cpp:195] accuracy does not need backward computation.
I0906 13:58:24.035605 16515 net.cpp:193] fc8_fc8_0_split needs backward computation.
I0906 13:58:24.035610 16515 net.cpp:193] fc8 needs backward computation.
I0906 13:58:24.035616 16515 net.cpp:193] relu7 needs backward computation.
I0906 13:58:24.035621 16515 net.cpp:193] fc7 needs backward computation.
I0906 13:58:24.035627 16515 net.cpp:193] relu6 needs backward computation.
I0906 13:58:24.035634 16515 net.cpp:193] fc6 needs backward computation.
I0906 13:58:24.035640 16515 net.cpp:193] pool5 needs backward computation.
I0906 13:58:24.035645 16515 net.cpp:193] relu5 needs backward computation.
I0906 13:58:24.035651 16515 net.cpp:193] conv5 needs backward computation.
I0906 13:58:24.035656 16515 net.cpp:193] relu4 needs backward computation.
I0906 13:58:24.035662 16515 net.cpp:193] conv4 needs backward computation.
I0906 13:58:24.035668 16515 net.cpp:193] relu3 needs backward computation.
I0906 13:58:24.035673 16515 net.cpp:193] conv3 needs backward computation.
I0906 13:58:24.035679 16515 net.cpp:193] pool2 needs backward computation.
I0906 13:58:24.035686 16515 net.cpp:193] norm2 needs backward computation.
I0906 13:58:24.035692 16515 net.cpp:193] relu2 needs backward computation.
I0906 13:58:24.035697 16515 net.cpp:193] conv2 needs backward computation.
I0906 13:58:24.035703 16515 net.cpp:193] pool1 needs backward computation.
I0906 13:58:24.035709 16515 net.cpp:193] norm1 needs backward computation.
I0906 13:58:24.035715 16515 net.cpp:193] relu1 needs backward computation.
I0906 13:58:24.035720 16515 net.cpp:193] conv1 needs backward computation.
I0906 13:58:24.035727 16515 net.cpp:195] label_data_1_split does not need backward computation.
I0906 13:58:24.035734 16515 net.cpp:195] data does not need backward computation.
I0906 13:58:24.035739 16515 net.cpp:236] This network produces output accuracy
I0906 13:58:24.035745 16515 net.cpp:236] This network produces output loss
I0906 13:58:24.035781 16515 net.cpp:483] Collecting Learning Rate and Weight Decay.
I0906 13:58:24.035796 16515 net.cpp:248] Network initialization done.
I0906 13:58:24.035799 16515 net.cpp:249] Memory required for data: 414724408
I0906 13:58:24.036000 16515 solver.cpp:53] Solver scaffolding done.
I0906 13:58:24.036130 16515 solver.cpp